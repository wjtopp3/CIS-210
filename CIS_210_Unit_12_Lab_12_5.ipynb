{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKyvmzhnNXYk4ZxlF3NYb3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjtopp3/CIS-210/blob/main/CIS_210_Unit_12_Lab_12_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ***forestfires.csv*** dataset contains meteorological information and the area burned for 517 forest fires that occurred in Montesinho Natural Park in Portugal. **Use principal component analysis to reduce the dimensions of the input data from 10 to a user-defined number**.\n",
        "\n",
        "- Initialize a **MinMaxScaler** and a **PCA model using scikit-lear**n with a user-input number of components.\n",
        "- **Scale the data and fit a principal component analysis model**.\n",
        "- Display the principal components, the amount of variance explained by the principal components, and the percentage variance explained by the principal components.\n",
        "\n",
        "Ex: If the input is:\n",
        "\n",
        "5\n",
        "\n",
        "the output should be:\n",
        "\n",
        "Components:\n",
        "         0       1       2       3  ...       6       7       8       9\n",
        "\n",
        "0  0.2258  0.1006 -0.0840 -0.4848  ... -0.3446  0.0913  0.1515 -0.0044\n",
        "\n",
        "1  0.8878  0.3773  0.0210  0.1610  ...  0.0786  0.0598 -0.0477  0.0128\n",
        "\n",
        "2 -0.0605 -0.0385 -0.0733  0.2430  ... -0.4770  0.7741  0.2490  0.0154\n",
        "\n",
        "3 -0.0400  0.0344 -0.0800 -0.1328  ... -0.1360  0.2432 -0.9376 -0.0161\n",
        "\n",
        "4  0.2818 -0.5737 -0.0475 -0.5525  ... -0.1931 -0.1028  0.0625 -0.0151\n",
        "\n",
        "\n",
        "[5 rows x 10 columns]\n",
        "\n",
        "Amount of explained variance:\n",
        "\n",
        " [0.133  0.0933 0.0498 0.0374 0.0221]\n",
        "\n",
        "Precent explained variance:\n",
        "\n",
        " [0.3566 0.2502 0.1336 0.1002 0.0592]"
      ],
      "metadata": {
        "id": "TGP09AH6MAmY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOgdHOB9L5hR"
      },
      "outputs": [],
      "source": [
        "# zyBooks Template\n",
        "# Import needed packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "fires = pd.read_csv('forestfires.csv')\n",
        "\n",
        "# Input the number of principal components\n",
        "nComp = int(input())\n",
        "\n",
        "# Define input and output features\n",
        "X = fires.drop(['month', 'day', 'area'], axis=1)\n",
        "y = fires[['area']]\n",
        "\n",
        "# Initialize a MinMaxScaler and a PCA model with a user-input number of components\n",
        "# Your code here\n",
        "\n",
        "# Scale the data and fit a principal component analysis model\n",
        "# Your code here\n",
        "\n",
        "# Display the principal components\n",
        "pcaComp = # Your code here\n",
        "print('Components:\\n', pd.DataFrame(np.round(pcaComp,4)))\n",
        "\n",
        "# Display the amount of variance explained by the principal components\n",
        "expVar = # Your code here\n",
        "print('Amount of explained variance:\\n', np.round(expVar,4))\n",
        "\n",
        "# Display the percentage variance explained by the principal components\n",
        "percExpVar = # Your code here\n",
        "print('Precent explained variance:\\n', np.round(percExpVar,4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zyBooks Solution\n",
        "# Import needed packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "fires = pd.read_csv('forestfires.csv')\n",
        "\n",
        "# Input the number of principal components\n",
        "nComp = int(input())\n",
        "\n",
        "# Define input and output features\n",
        "X = fires.drop(['month', 'day', 'area'], axis=1)\n",
        "y = fires[['area']]\n",
        "\n",
        "# Initialize a MinMaxScaler and a PCA model with a user-input number of components\n",
        "scaler = MinMaxScaler()\n",
        "pca = PCA(n_components=nComp)\n",
        "\n",
        "# Scale the data and fit a principal component analysis model\n",
        "pipeline_pca = Pipeline(steps=[('scaler',scaler),('pca',pca)])\n",
        "pipeline_pca.fit(X, np.ravel(y))\n",
        "\n",
        "# Display the principal components\n",
        "pcaComp = pca.components_\n",
        "print('Components:\\n', pd.DataFrame(np.round(pcaComp,4)))\n",
        "\n",
        "# Display the amount of variance explained by the principal components\n",
        "expVar = pca.explained_variance_\n",
        "print('Amount of explained variance:\\n', np.round(expVar,4))\n",
        "\n",
        "# Display the percentage variance explained by the principal components\n",
        "percExpVar = pca.explained_variance_ratio_\n",
        "print('Precent explained variance:\\n', np.round(percExpVar,4))"
      ],
      "metadata": {
        "id": "UBvfOGUsMayZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Claude Solution\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Read the dataset\n",
        "df = pd.read_csv('forestfires.csv')\n",
        "\n",
        "# Get the number of components from user input\n",
        "n_components = int(input())\n",
        "\n",
        "# Assume we need to use all numeric features except 'area' (target variable)\n",
        "# Select the input features (10 features as mentioned)\n",
        "# Adjust column selection based on your actual dataset structure\n",
        "# Typically includes: X, Y, month, day, FFMC, DMC, DC, ISI, temp, RH, wind, rain\n",
        "# Convert categorical variables if needed, or select only numeric columns\n",
        "X = df.select_dtypes(include=[np.number]).iloc[:, :-1]  # Exclude last column (area)\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Scale the data\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Initialize PCA model with user-defined number of components\n",
        "pca = PCA(n_components=n_components)\n",
        "\n",
        "# Fit the PCA model\n",
        "pca.fit(X_scaled)\n",
        "\n",
        "# Get the principal components\n",
        "components = pd.DataFrame(pca.components_)\n",
        "\n",
        "# Get the explained variance\n",
        "explained_variance = pca.explained_variance_\n",
        "\n",
        "# Get the explained variance ratio (percentage)\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Display results\n",
        "print(\"Components:\")\n",
        "print(components)\n",
        "print(\"Amount of explained variance:\")\n",
        "print(f\" {explained_variance}\")\n",
        "print(\"Precent explained variance:\")\n",
        "print(f\" {explained_variance_ratio}\")"
      ],
      "metadata": {
        "id": "kJZC0XyjMbTy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}